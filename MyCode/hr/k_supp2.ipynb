{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from dl85 import DL85Predictor\n",
    "from dl85 import DL85Classifier\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import utils\n",
    "import graphviz\n",
    "import multiprocessing\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "FILE_NAME = \"HR\"\n",
    "\n",
    "# src: https://www.kaggle.com/hjmjerry/gender-discrimination\n",
    "df = pandas.read_csv(\"../dataset_perso/HRDataset_v14.csv\")\n",
    "del df['Employee_Name']\n",
    "del df['EmpID']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "salary_mean = np.mean(np.array(df[\"Salary\"].tolist(), float))\n",
    "print(f\"Mean: {salary_mean}\")\n",
    "for i in range(0,len(df)):\n",
    "    if df.at[i, \"Salary\"] >= salary_mean:\n",
    "        df.at[i, \"Salary_mean\"] = 1\n",
    "    else:\n",
    "        df.at[i, \"Salary_mean\"] = 0\n",
    "del df[\"Salary\"]\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    df.at[i, \"Absences\"] = df.at[i, \"Absences\"] / 5\n",
    "for i in range(0,len(df)):\n",
    "    df.at[i, \"EngagementSurvey\"] = int(df.at[i, \"EngagementSurvey\"])\n",
    "for i in range(0,len(df)):\n",
    "    if df.at[i, \"HispanicLatino\"] == 'Yes' or df.at[i, \"HispanicLatino\"] == 'yes' :\n",
    "        df.at[i, \"HispanicLatino\"] = 1\n",
    "    elif df.at[i, \"HispanicLatino\"] == 'No' or df.at[i, \"HispanicLatino\"] == 'no' :\n",
    "        df.at[i, \"HispanicLatino\"] = 0\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "col = ['EmpStatusID', 'PerfScoreID', 'Position', 'MaritalDesc', 'CitizenDesc', 'RaceDesc', 'Department', 'PerformanceScore', 'EmpSatisfaction', 'Absences']\n",
    "df = df.drop(['MarriedID', 'MaritalStatusID', 'Zip', 'DOB', 'Sex', 'DateofHire','DateofTermination', 'TermReason', 'EmploymentStatus', 'ManagerName', 'ManagerID', 'EngagementSurvey', 'LastPerformanceReview_Date', 'DaysLateLast30', 'RecruitmentSource', 'State', 'DeptID', 'PositionID', 'SpecialProjectsCount'], axis=1)\n",
    "df = pd.get_dummies(df, columns=col)\n",
    "for col in df:\n",
    "    if len(df[col].unique()) > 2:\n",
    "        print(f'{col}: {df[col].unique()}')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = df.loc[:, ~df.columns.isin(['Gender', 'Salary_mean'])]\n",
    "y = df['Salary_mean']\n",
    "sensitive = df['GenderID']\n",
    "print(utils.discrimination(y, sensitive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(df)):\n",
    "    if df.at[i, \"GenderID\"] == 1:\n",
    "        df.at[i, \"GenderID\"] = 0\n",
    "    else:\n",
    "        df.at[i, \"GenderID\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = df.loc[:, ~df.columns.isin(['Gender', 'Salary_mean'])]\n",
    "y = df['Salary_mean']\n",
    "sensitive = df['GenderID']\n",
    "print(utils.discrimination(y, sensitive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, sensitive_train, sensitive_test = utils.train_test_split(1, X, y, sensitive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from multiprocessing import Process, Pool\n",
    "from functools import partial\n",
    "\n",
    "result = pd.DataFrame(columns=\n",
    "                      [\"k\", \"depth\", \"random_state\", \"clf.error_\", \"clf.accuracy_\",\"confusion\", \"accuracy_pred\", \"accuracy_test\", \"sum_misclassified_train\",\n",
    "                        \"discrimination_train\",       \"sum_discrimination_additive_train\",      \"sum_discrimination_additive_train_abs\",\n",
    "                        \"discrimination_train_pred\",  \"sum_discrimination_additive_train_pred\", \"sum_discrimination_additive_train_pred_abs\",\n",
    "                        \"discrimination_test\",        \"sum_discrimination_additive_test_pred\",  \"sum_discrimination_additive_test_pred_abs\",\n",
    "                        \"duration\", \"min_supp\", \"clf.tree_\"])\n",
    "\n",
    "def xx(min_supp, random_state, X_train, X_test, y_train, y_test, sensitive_train, sensitive_test, depth, k):\n",
    "\n",
    "    clf = DL85Classifier(max_depth=depth, error_function=lambda tids: utils.error(list(tids), k, y_train, sensitive_train), min_sup=min_supp, time_limit=300)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    clf.fit(X_train, list(y_train))\n",
    "    duration = time.perf_counter() - start\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    accuracy_pred = round(accuracy_score(y_train, y_pred_train), 8)\n",
    "    accuracy_test = round(accuracy_score(y_test, y_pred_test), 8)\n",
    "    discrimination_train = round(utils.discrimination(y_train, sensitive_train), 8)\n",
    "    discrimination_train_pred = round(utils.discrimination(y_pred_train, sensitive_train), 8)\n",
    "    discrimination_test = round(utils.discrimination(y_pred_test, sensitive_test), 8)\n",
    "\n",
    "    utils.tree_upgrade(clf.tree_, y_train, np.asarray(y_pred_train), sensitive_train)\n",
    "    sum_discrimination_additive_train_pred = round(utils.sum_elem_tree(ast.literal_eval(str(clf.tree_)), 'discrimination_additive_pred', do_abs=False),8)\n",
    "    sum_discrimination_additive_train_pred_abs = round(utils.sum_elem_tree(ast.literal_eval(str(clf.tree_)), 'discrimination_additive_pred', do_abs=True),8)\n",
    "\n",
    "    sum_discrimination_additive_train = round(utils.sum_elem_tree(ast.literal_eval(str(clf.tree_)), 'discrimination_additive_train', do_abs=False),8)\n",
    "    sum_discrimination_additive_train_abs = round(utils.sum_elem_tree(ast.literal_eval(str(clf.tree_)), 'discrimination_additive_train', do_abs=True),8)\n",
    "    sum_misclassified_train = round(utils.sum_elem_tree(clf.tree_, 'misclassified'),8)\n",
    "\n",
    "    discri_test= list()\n",
    "    utils.get_discri_test(clf.tree_, X_test, y_pred_test, sensitive_test, discri_test, X.columns, path=None)\n",
    "    sum_discrimination_additive_test_pred = sum(discri_test)\n",
    "    sum_discrimination_additive_test_pred_abs = 0\n",
    "    [sum_discrimination_additive_test_pred_abs := sum_discrimination_additive_test_pred_abs + abs(d) for d in discri_test]\n",
    "    #print(f\"### Depth: {depth} state: {random_state} k:{k} ###\")\n",
    "\n",
    "    return [k, depth, random_state, clf.error_, clf.accuracy_, utils.perf_measure(y_train, y_pred_train, sensitive_train), accuracy_pred, accuracy_test, sum_misclassified_train,\n",
    "            discrimination_train,       sum_discrimination_additive_train,      sum_discrimination_additive_train_abs,\n",
    "            discrimination_train_pred,  sum_discrimination_additive_train_pred, sum_discrimination_additive_train_pred_abs,\n",
    "            discrimination_test,        sum_discrimination_additive_test_pred,  sum_discrimination_additive_test_pred_abs,\n",
    "            duration, min_supp, clf.tree_]\n",
    "\n",
    "pool = Pool()\n",
    "if False:\n",
    "    min_supp = 2\n",
    "    args = []\n",
    "    #result = pd.read_csv('save/'+FILE_NAME+\".csv\")\n",
    "    for depth in [1, 2, 3, 4, 5, 6, 7]:\n",
    "        for k in [0, 10, 50, 100, 200, 300, 400, 500, 1000, 5000, 100000]:\n",
    "            args.append((depth, k))\n",
    "    for random_state in tqdm(range(1, 101, 5)):\n",
    "        if random_state in [46]:\n",
    "                continue\n",
    "        result = pd.DataFrame(columns=\n",
    "                      [\"k\", \"depth\", \"random_state\", \"clf.error_\", \"clf.accuracy_\",\"confusion\", \"accuracy_pred\", \"accuracy_test\", \"sum_misclassified_train\",\n",
    "                        \"discrimination_train\",       \"sum_discrimination_additive_train\",      \"sum_discrimination_additive_train_abs\",\n",
    "                        \"discrimination_train_pred\",  \"sum_discrimination_additive_train_pred\", \"sum_discrimination_additive_train_pred_abs\",\n",
    "                        \"discrimination_test\",        \"sum_discrimination_additive_test_pred\",  \"sum_discrimination_additive_test_pred_abs\",\n",
    "                        \"duration\", \"min_supp\", \"clf.tree_\"])\n",
    "        X_train, X_test, y_train, y_test, sensitive_train, sensitive_test = utils.train_test_split(random_state, X, y, sensitive)\n",
    "        \n",
    "        \n",
    "        for res in pool.starmap(partial(xx, min_supp, random_state, X_train, X_test, y_train, y_test, sensitive_train, sensitive_test), tqdm(args)):\n",
    "            result.loc[len(result.index)] = res\n",
    "\n",
    "\n",
    "        #result = result.sort_values(['k', 'depth', 'min_supp'])\n",
    "        result.to_csv('save/'+FILE_NAME+\"_\"+str(random_state)+'.csv', index=False)\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "result = pd.DataFrame(columns=\n",
    "                      [\"k\", \"depth\", \"random_state\", \"clf.error_\", \"clf.accuracy_\",\"confusion\", \"accuracy_pred\", \"accuracy_test\", \"sum_misclassified_train\",\n",
    "                        \"discrimination_train\",       \"sum_discrimination_additive_train\",      \"sum_discrimination_additive_train_abs\",\n",
    "                        \"discrimination_train_pred\",  \"sum_discrimination_additive_train_pred\", \"sum_discrimination_additive_train_pred_abs\",\n",
    "                        \"discrimination_test\",        \"sum_discrimination_additive_test_pred\",  \"sum_discrimination_additive_test_pred_abs\",\n",
    "                        \"duration\", \"min_supp\", \"clf.tree_\"]) \n",
    "for random_state in tqdm(range(1, 101, 5)):\n",
    "    if random_state in [46]:\n",
    "            continue\n",
    "    result = pd.concat([result, pd.read_csv('save/'+FILE_NAME+\"_\"+str(random_state)+'.csv')])\n",
    "result.to_csv('save/'+FILE_NAME+'.csv', index=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test, sensitive_train, sensitive_test = utils.train_test_split(1, X, y, sensitive)\n",
    "\n",
    "clf = DL85Classifier(max_depth=3, error_function=lambda tids: utils.error(list(tids), 10, y_train, sensitive_train), min_sup=1, time_limit=600)\n",
    "clf.fit(X_train, list(y_train))\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "print(f'accuracy_pred = {round(accuracy_score(y_train, y_pred_train), 8)}')\n",
    "print(f'accuracy_test = {round(accuracy_score(y_test, y_pred_test), 8)}')\n",
    "print(f'discrimination_train = {round(utils.discrimination(y_train, sensitive_train), 8)}')\n",
    "print(f'discrimination_train_pred = {round(utils.discrimination(y_pred_train, sensitive_train), 8)}')\n",
    "\n",
    "utils.tree_upgrade(clf.tree_, y_train, np.asarray(y_pred_train), sensitive_train)\n",
    "dot = utils.export_graphviz(clf)\n",
    "graph = graphviz.Source(dot, format=\"png\")\n",
    "graph.render(\"plots/\"+FILE_NAME+\"tree\")\n",
    "graphviz.Source(dot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "discri_test= list()\n",
    "utils.get_discri_test(clf.tree_, X_test, y_test, sensitive_test, discri_test, X.columns, path=None)\n",
    "sum_discrimination_additive_test_pred = sum(discri_test)\n",
    "sum_discrimination_additive_test_pred_abs = 0\n",
    "[sum_discrimination_additive_test_pred_abs := sum_discrimination_additive_test_pred_abs + abs(d) for d in discri_test]\n",
    "print(sum_discrimination_additive_test_pred)\n",
    "sum_discrimination_additive_test_pred_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "discri_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utils.discrimination(y_train, sensitive_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(utils.sum_elem_tree(clf.tree_, 'discrimination_additive_train'))\n",
    "print(utils.sum_elem_tree(clf.tree_, 'discrimination_additive_train', do_abs=True))\n",
    "print(utils.sum_elem_tree(clf.tree_, 'discrimination_additive_pred'))\n",
    "print(utils.sum_elem_tree(clf.tree_, 'discrimination_additive_pred', do_abs=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utils.sum_elem_tree(clf.tree_, 'misclassified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(utils.discrimination(y_train, sensitive_train))\n",
    "print(utils.discrimination(y_pred_train, sensitive_train))\n",
    "print(utils.discrimination(y_test, sensitive_test))\n",
    "print(utils.discrimination(y_pred_test, sensitive_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clf.tree_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot_mean(\"depth\", \"discrimination_train_pred\", result, 0, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot_mean(\"depth\", \"discrimination_test\", result, 0, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot_mean(\"depth\", \"clf.accuracy_\", result, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot_mean(\"depth\", \"accuracy_pred\", result, 0.5, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot_mean(\"depth\", \"accuracy_test\", result, 0.5, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot2(\"accuracy_pred\", \"discrimination_train_pred\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot2(\"accuracy_test\", \"discrimination_test\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot_one_scatter_by_depth(\"accuracy_pred\", \"discrimination_train_pred\", result, (0.6, 1), (0, 0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot_one_scatter_by_depth(\"accuracy_test\", \"discrimination_test\", result, (0, 1), (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot_one_scatter_by_depth(\"clf.error_\", \"discrimination_train_pred\", result, (0, 600), (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot_one_scatter_by_depth(\"sum_misclassified_train\", \"discrimination_train_pred\", result, (0, 60), (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot_one_scatter_by_depth(\"sum_discrimination_additive_train_pred\", \"discrimination_train_pred\", result, (0, 1), (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot_one_scatter_by_depth(\"sum_discrimination_additive_train_pred\", \"accuracy_pred\", result, (0, 1), (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_lim = (0.84, 0.95)\n",
    "y_lim = (0.2, 0.3)\n",
    "utils.plot_k_depth_mean(\"accuracy_pred\", \"discrimination_train_pred\", result, x_lim, y_lim)\n",
    "utils.plot_each_k_depth_mean(\"accuracy_pred\", \"discrimination_train_pred\", result, x_lim, y_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_lim = (0.84, 0.95)\n",
    "y_lim = (0.2, 0.3)\n",
    "utils.plot_k_depth_mean(\"accuracy_test\", \"discrimination_test\", result, x_lim, y_lim)\n",
    "utils.plot_each_k_depth_mean(\"accuracy_test\", \"discrimination_test\", result, x_lim, y_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_lim = None\n",
    "y_lim = None\n",
    "utils.plot_k_depth_mean(\"clf.error_\", \"discrimination_train_pred\", result, x_lim, y_lim)\n",
    "utils.plot_each_k_depth_mean(\"clf.error_\", \"discrimination_train_pred\", result, x_lim, y_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_lim = None\n",
    "y_lim = None\n",
    "utils.plot_k_depth_mean(\"sum_misclassified_train\", \"discrimination_train_pred\", result, x_lim, y_lim)\n",
    "utils.plot_each_k_depth_mean(\"sum_misclassified_train\", \"discrimination_train_pred\", result, x_lim, y_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_lim = None\n",
    "y_lim = None\n",
    "utils.plot_k_depth_mean(\"sum_misclassified_train\", \"discrimination_train_pred\", result, x_lim, y_lim)\n",
    "utils.plot_each_k_depth_mean(\"sum_misclassified_train\", \"discrimination_train_pred\", result, x_lim, y_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_lim = None\n",
    "y_lim = None\n",
    "utils.plot_k_depth_mean(\"sum_discrimination_additive_train_pred\", \"discrimination_train_pred\", result, x_lim, y_lim)\n",
    "utils.plot_each_k_depth_mean(\"sum_discrimination_additive_train_pred\", \"discrimination_train_pred\", result, x_lim, y_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_lim = None\n",
    "y_lim = None\n",
    "utils.plot_k_depth_mean(\"sum_discrimination_additive_train_pred\", \"sum_discrimination_additive_train_pred_abs\", result, x_lim, y_lim)\n",
    "utils.plot_each_k_depth_mean(\"sum_discrimination_additive_train_pred\", \"sum_discrimination_additive_train_pred_abs\", result, x_lim, y_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91b3042644fc76fe48ba76245780156751ae4c80307eab167c6865bf43871907"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
