{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from MyCode import relabeling_fairlearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "round_value = 15"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19451574596420296\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    from tqdm import tqdm\n",
    "    from fairlearn.datasets import fetch_adult\n",
    "\n",
    "    dataset = fetch_adult(as_frame=True)\n",
    "    df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "    df['>50k'] = (dataset.target == '>50K') * 1\n",
    "\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df['sex'] = le.fit_transform(df['sex'])\n",
    "\n",
    "    onehot = ['workclass', 'education', 'marital-status', 'occupation', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "    df = pd.get_dummies(df,prefix=onehot, columns = onehot, drop_first=True)\n",
    "    tmp = df['sex'].to_list()\n",
    "    for i in range(0,len(tmp)):\n",
    "        if tmp[i] == 1:\n",
    "            tmp[i] = 0\n",
    "        else:\n",
    "            tmp[i] = 1\n",
    "    df['sex'] = tmp\n",
    "    y = df[\">50k\"]\n",
    "    sensitive = df['sex']\n",
    "    X = df.loc[:, ~df.columns.isin(['sex', '>50k', 'native-country'])]\n",
    "    print(relabeling_fairlearn.discrimination_dataset(y, sensitive))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "if False:\n",
    "    pd.set_option('max_columns', None)\n",
    "    FILE_NAME = \"relab_Lawsuit\"\n",
    "\n",
    "    # src: https://www.kaggle.com/hjmjerry/gender-discrimination\n",
    "    df = pandas.read_csv(\"dataset_perso/Lawsuit.csv\")\n",
    "    del df['ID']\n",
    "    salary_mean = np.mean(np.array(df[\"Sal94\"].tolist(), float))\n",
    "    for i in range(0,len(df)):\n",
    "        if df.at[i, \"Sal94\"] >= salary_mean:\n",
    "            df.at[i, \"Salary_mean\"] = 1\n",
    "        else:\n",
    "            df.at[i, \"Salary_mean\"] = 0\n",
    "    del df[\"Sal94\"]\n",
    "    del df[\"Sal95\"]\n",
    "    col = ['Rank', 'Dept']\n",
    "    df = df.drop(['Prate', 'Exper'], axis=1)\n",
    "    df = pd.get_dummies(df, columns=col)\n",
    "    for i in range(0,len(df)):\n",
    "        if df.at[i, \"Gender\"] == 1:\n",
    "            df.at[i, \"Gender\"] = 0\n",
    "        else:\n",
    "            df.at[i, \"Gender\"] = 1\n",
    "    X = df.loc[:, ~df.columns.isin(['Gender', 'Salary_mean'])]\n",
    "    y = df['Salary_mean']\n",
    "    sensitive = df['Gender']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "if False:\n",
    "    pd.set_option('max_columns', None)\n",
    "    FILE_NAME = \"HR\"\n",
    "\n",
    "    # src: https://www.kaggle.com/hjmjerry/gender-discrimination\n",
    "    df = pandas.read_csv(\"dataset_perso/HRDataset_v14.csv\")\n",
    "    del df['Employee_Name']\n",
    "    del df['EmpID']\n",
    "    salary_mean = np.mean(np.array(df[\"Salary\"].tolist(), float))\n",
    "    print(f\"Mean: {salary_mean}\")\n",
    "    for i in range(0,len(df)):\n",
    "        if df.at[i, \"Salary\"] >= salary_mean:\n",
    "            df.at[i, \"Salary_mean\"] = 1\n",
    "        else:\n",
    "            df.at[i, \"Salary_mean\"] = 0\n",
    "    del df[\"Salary\"]\n",
    "\n",
    "    for i in range(0,len(df)):\n",
    "        df.at[i, \"Absences\"] = df.at[i, \"Absences\"] / 5\n",
    "    for i in range(0,len(df)):\n",
    "        df.at[i, \"EngagementSurvey\"] = int(df.at[i, \"EngagementSurvey\"])\n",
    "    for i in range(0,len(df)):\n",
    "        if df.at[i, \"HispanicLatino\"] == 'Yes' or df.at[i, \"HispanicLatino\"] == 'yes' :\n",
    "            df.at[i, \"HispanicLatino\"] = 1\n",
    "        elif df.at[i, \"HispanicLatino\"] == 'No' or df.at[i, \"HispanicLatino\"] == 'no' :\n",
    "            df.at[i, \"HispanicLatino\"] = 0\n",
    "    col = ['EmpStatusID', 'PerfScoreID', 'Position', 'MaritalDesc', 'CitizenDesc', 'RaceDesc', 'Department', 'PerformanceScore', 'EmpSatisfaction', 'Absences']\n",
    "    df = df.drop(['MarriedID', 'MaritalStatusID', 'Zip', 'DOB', 'Sex', 'DateofHire','DateofTermination', 'TermReason', 'EmploymentStatus', 'ManagerName', 'ManagerID', 'EngagementSurvey', 'LastPerformanceReview_Date', 'DaysLateLast30', 'RecruitmentSource', 'State', 'DeptID', 'PositionID', 'SpecialProjectsCount'], axis=1)\n",
    "    df = pd.get_dummies(df, columns=col)\n",
    "    for col in df:\n",
    "        if len(df[col].unique()) > 2:\n",
    "            print(f'{col}: {df[col].unique()}')\n",
    "    for i in range(0,len(df)):\n",
    "        if df.at[i, \"GenderID\"] == 1:\n",
    "            df.at[i, \"GenderID\"] = 0\n",
    "        else:\n",
    "            df.at[i, \"GenderID\"] = 1\n",
    "    X = df.loc[:, ~df.columns.isin(['Gender', 'Salary_mean'])]\n",
    "    y = df['Salary_mean']\n",
    "    sensitive = df['GenderID']\n",
    "    print(relabeling_fairlearn.discrimination_dataset(y, sensitive))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "if False:\n",
    "    data_url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
    "    data_url = \"dataset_perso/default of credit card clients.xls\"\n",
    "    dataset = pd.read_excel(io=data_url, header=1).drop(columns=['ID']).rename(columns={'PAY_0':'PAY_1'})\n",
    "\n",
    "    tmp = dataset['SEX'].to_list()\n",
    "    for i in range(0,len(tmp)):\n",
    "        if tmp[i] == 1:\n",
    "            tmp[i] = 0\n",
    "        elif tmp[i] == 2:\n",
    "            tmp[i] = 1\n",
    "        else:\n",
    "            raise Exception(i)\n",
    "\n",
    "    dataset[\"SEX\"] = tmp\n",
    "    sensitive = dataset[\"SEX\"]\n",
    "    y = dataset[\"default payment next month\"]\n",
    "    X = dataset.loc[:, ~dataset.columns.isin(['SEX', 'default payment next month'])]\n",
    "    categorical_features = ['EDUCATION', 'MARRIAGE','PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "    for col in categorical_features:\n",
    "        dataset[col] = dataset[col].astype('category')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1925655508416967\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(random_state, X, y, sensitive):\n",
    "    index_train = list(X.sample(frac=0.8, random_state=random_state).index)\n",
    "    index_test = list(X.drop(index=index_train).index)\n",
    "\n",
    "    X_train = X.drop(index=index_test).to_numpy()\n",
    "    y_train = y.drop(index=index_test).to_numpy()\n",
    "    sensitive_train = sensitive.drop(index=index_test).to_numpy()\n",
    "\n",
    "    X_test = X.drop(index=index_train).to_numpy()\n",
    "    y_test = list(y.drop(index=index_train).to_numpy())\n",
    "    sensitive_test = sensitive.drop(index=index_train).to_numpy()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, sensitive_train, sensitive_test\n",
    "\n",
    "X_train, X_test, y_train, y_test, sensitive_train, sensitive_test = train_test_split(1, X, y, sensitive)\n",
    "print(relabeling_fairlearn.discrimination_dataset(y_train, sensitive_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Basic usage"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the prediction:  0.839612018221836\n",
      "Discrimination of classifier on the predidiction:  0.18826592982247\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "clf.fit(X_train, list(y_train))\n",
    "y_pred = clf.predict(X_train)\n",
    "accuracy = round(accuracy_score(y_train, y_pred),round_value)\n",
    "print(\"Accuracy of the prediction: \", accuracy)\n",
    "discrimination= round(relabeling_fairlearn.discrimination_dataset(y_pred, sensitive_train), round_value)\n",
    "print(\"Discrimination of classifier on the predidiction: \", discrimination)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Raises an exception\n",
    "sensitive = list(sensitive)\n",
    "sensitive[0] = 2\n",
    "sensitive = np.asarray(sensitive)\n",
    "print(sensitive)\n",
    "print(np.unique(sensitive))\n",
    "\"\"\"\n",
    "threshold = 0.1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;33mUnable to reach the threshold.\u001B[0m\n",
      "Accuracy of the prediction:  0.768311409121155\n",
      "Discrimination of classifier on the prediction:  0.055832129864993\n"
     ]
    }
   ],
   "source": [
    "relabeling_fairlearn.relabeling(clf, X_train, y_train, y_pred, sensitive_train, threshold)\n",
    "y_pred_relab = clf.predict(X_train)\n",
    "accuracy_relab = round(accuracy_score(y_train, y_pred_relab),round_value)\n",
    "print(\"Accuracy of the prediction: \", accuracy_relab)\n",
    "discrimination_relab = round(relabeling_fairlearn.discrimination_dataset(y_pred_relab, sensitive_train), round_value)\n",
    "print(\"Discrimination of classifier on the prediction: \", discrimination_relab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Detailed operations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the prediction:  0.839612018221836\n",
      "Discrimination of classifier on the prediction:  0.18826592982247\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "clf.fit(X_train, list(y_train))\n",
    "y_pred = clf.predict(X_train)\n",
    "accuracy = round(accuracy_score(y_train, y_pred), round_value)\n",
    "print(\"Accuracy of the prediction: \", accuracy)\n",
    "discrimination= round(relabeling_fairlearn.discrimination_dataset(y_pred, sensitive_train), round_value)\n",
    "print(\"Discrimination of classifier on the prediction: \", discrimination)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "threshold = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: format -> (feature, type, node id)\n",
      "((67, 'left', 0), (3, 'left', 1), (2, 'right', 2), (-2, 'leaf', 4)) \n",
      "node_id: 4 \n",
      "The effect of relabeling the leaf on accuracy: -0.0009213381925392081\n",
      "The effect of relabeling the leaf on discrimination: -0.000284707552251996 \n",
      "-(18 + 0) / 16192 + (27 + 0) / 32650= -0.000284707552251996 \n",
      "ratio: 0.30901525037982197 \n",
      "contingency table: \n",
      "[0.0003685352770156832, 0.0]\n",
      "[0.0005528029155235249, 0.0]\n",
      "transactions: [838, 861, 1205, 1924, 2002, 3549, 5871, 6198, 6227, 8590, 8634, 8777, 9169, 9354, 10860, 11342, 12542, 13207, 15930, 18716, 19385, 19534, 19538, 19545, 20077, 21294, 23631, 25090, 26302, 27750, 30138, 30150, 30474, 30764, 31370, 33072, 33081, 33171, 33510, 33735, 34696, 34762, 35707, 38912, 38972]\n"
     ]
    }
   ],
   "source": [
    "i = list()\n",
    "cnt = np.unique(sensitive, return_counts=True)[1]\n",
    "relabeling_fairlearn.get_leaves_candidates(clf, X_train, y_train, sensitive_train, cnt, len(y), i)\n",
    "for e in i:\n",
    "    print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;33mUnable to reach the threshold.\u001B[0m\n",
      "Path: format -> (feature, type, node id)\n",
      "((67, 'left', 0), (3, 'left', 1), (2, 'right', 2), (-2, 'leaf', 4)) \n",
      "node_id: 4 \n",
      "The effect of relabeling the leaf on accuracy: -0.0011516609510160208\n",
      "The effect of relabeling the leaf on discrimination: -0.00036334813001866325 \n",
      "-(18 + 0) / 12903 + (27 + 0) / 26171= -0.00036334813001866325 \n",
      "ratio: 0.31549921849664997 \n",
      "contingency table: \n",
      "[0.00046066438040640837, 0.0]\n",
      "[0.0006909965706096125, 0.0]\n",
      "transactions: [838, 861, 1205, 1924, 2002, 3549, 5871, 6198, 6227, 8590, 8634, 8777, 9169, 9354, 10860, 11342, 12542, 13207, 15930, 18716, 19385, 19534, 19538, 19545, 20077, 21294, 23631, 25090, 26302, 27750, 30138, 30150, 30474, 30764, 31370, 33072, 33081, 33171, 33510, 33735, 34696, 34762, 35707, 38912, 38972]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leafs_relab = relabeling_fairlearn.leaves_to_relabel(clf, X_train, y_train, y_pred, sensitive_train, threshold)\n",
    "\n",
    "sum_acc = 0\n",
    "sum_disc = 0\n",
    "for l in leafs_relab:\n",
    "    print(l)\n",
    "    print()\n",
    "    sum_acc += l.acc\n",
    "    sum_disc += l.disc\n",
    "sum_acc = round(sum_acc, round_value)\n",
    "sum_disc = round(sum_disc, round_value)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;33mUnable to reach the threshold.\u001B[0m\n",
      "Accuracy:\n",
      "    Before      : 0.839612018221836\n",
      "    After       : 0.768311409121155\n",
      "    Expected    : 0.83846035727082\n",
      "    Leafs       : -0.001151660951016\n",
      "    Difference  : -0.07130060910068092\n",
      "    Check       : False\n",
      "Discrimination:\n",
      "    Before      : 0.18826592982247\n",
      "    After       : 0.055832129864993\n",
      "    Expected    : 0.187902581692451\n",
      "    Leafs       : -0.000363348130019\n",
      "    Difference  : -0.132433799957477\n",
      "    Check       : False\n"
     ]
    }
   ],
   "source": [
    "relabeling_fairlearn.relabeling(clf, X_train, y_train, y_pred, sensitive_train, threshold)\n",
    "y_pred_relab = clf.predict(X_train)\n",
    "accuracy_relab = round(accuracy_score(y_train, y_pred_relab), round_value)\n",
    "discrimination_relab = round(relabeling_fairlearn.discrimination_dataset(y_pred_relab, sensitive_train), round_value)\n",
    "new_acc= round(accuracy+sum_acc, round_value)\n",
    "new_disc = round(discrimination+sum_disc, round_value)\n",
    "print(f\"Accuracy:\\n\"\n",
    "    f\"    Before      : {accuracy}\\n\"\n",
    "    f\"    After       : {accuracy_relab}\\n\"\n",
    "    f\"    Expected    : {new_acc}\\n\"\n",
    "    f\"    Leafs       : {sum_acc}\\n\"\n",
    "    f\"    Difference  : {-accuracy+accuracy_relab}\\n\"\n",
    "    f\"    Check       : {new_acc == accuracy_relab}\")\n",
    "print(f\"Discrimination:\\n\"\n",
    "    f\"    Before      : {discrimination}\\n\"\n",
    "    f\"    After       : {discrimination_relab}\\n\"\n",
    "    f\"    Expected    : {new_disc}\\n\"\n",
    "    f\"    Leafs       : {sum_disc }\\n\"\n",
    "    f\"    Difference  : {-discrimination+discrimination_relab}\\n\"\n",
    "    f\"    Check       : {new_disc== discrimination_relab}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: format -> (feature, type, node id)\n",
      "((67, 'left', 0), (3, 'left', 1), (2, 'right', 2), (-2, 'leaf', 4)) \n",
      "node_id: 4 \n",
      "The effect of relabeling the leaf on accuracy: -0.0011516609510160208\n",
      "The effect of relabeling the leaf on discrimination: -0.00036334813001866325 \n",
      "-(18 + 0) / 12903 + (27 + 0) / 26171= -0.00036334813001866325 \n",
      "ratio: 0.31549921849664997 \n",
      "contingency table: \n",
      "[0.00046066438040640837, 0.0]\n",
      "[0.0006909965706096125, 0.0]\n",
      "transactions: [838, 861, 1205, 1924, 2002, 3549, 5871, 6198, 6227, 8590, 8634, 8777, 9169, 9354, 10860, 11342, 12542, 13207, 15930, 18716, 19385, 19534, 19538, 19545, 20077, 21294, 23631, 25090, 26302, 27750, 30138, 30150, 30474, 30764, 31370, 33072, 33081, 33171, 33510, 33735, 34696, 34762, 35707, 38912, 38972]\n"
     ]
    }
   ],
   "source": [
    "l = list(leafs_relab)[0]\n",
    "print(l)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) (26171, 12903)\n",
      "(0 / 26171) - (0 / 12903))\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.0"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "utils.discr_add(l.transactions, y_train, sensitive_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}